---
---

@Article{sym15091627,
AUTHOR = {Jadon, Shruti and Taluri, Saisamarth and Birthi, Sakshi and Mahesh, Sanjana and Kumar, Sankalp and Shashidhar, Sai Shruthi and Honnavalli, Prasad B.},
TITLE = {An Assistive Model for the Visually Impaired Integrating the Domains of IoT, Blockchain and Deep Learning},
JOURNAL = {Symmetry},
VOLUME = {15},
YEAR = {2023},
NUMBER = {9},
ARTICLE-NUMBER = {1627},
URL = {https://www.mdpi.com/2073-8994/15/9/1627},
ISSN = {2073-8994},
ABSTRACT = {Internet of Things, blockchain and deep learning are emerging technologies that have recently gained popularity due to their various benefits and applications. All three domains have had success independently in various applications such as automation, agriculture, travel, finance, image recognition, speech recognition, and many others. This paper proposes an efficient, lightweight, and user-friendly solution to help visually impaired individuals navigate their way by taking advantage of modern technologies. The proposed method involves the usage of a camera lens attached to a Raspberry Pi device to capture live video frames of the user’s environment, which are then transmitted to cloud storage. The link to access these images is stored within a symmetrical private blockchain network (no superior access), where all deep learning servers act as nodes. The deep learning model deployed on these servers analyses the video frames to detect objects and feeds the output back to the cloud service. Ultimately, the user receives audio notifications about obstacles through an earphone plugged into the Raspberry Pi. In particular, when running the model on a high-performing network and an RTX 3090 GPU, the average obstacle notification time is reported within 2 s, highlighting the proposed system’s responsiveness and effectiveness in aiding visually impaired individuals.},
DOI = {10.3390/sym15091627},
preview={human-ai.gif}
}

@article{SK2024329,
title = {PowerTrain: Fast, generalizable time and power prediction models to optimize DNN training on accelerated edges},
journal = {Future Generation Computer Systems},
volume = {161},
pages = {329-344},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24003649},
author = {Prashanthi S.K. and Saisamarth Taluri and Beautlin S and Lakshya Karwa and Yogesh Simmhan},
keywords = {Edge computing, Edge accelerators, DNN training, Performance modeling, Performance optimization},
abstract = {Accelerated edge devices, like Nvidia’s Jetson with 1000+ CUDA cores, are increasingly used for DNN training and federated learning, rather than just for inferencing workloads. A unique feature of these compact devices is their fine-grained control over CPU, GPU, memory frequencies, and active CPU cores, which can limit their power envelope in a constrained setting while throttling the compute performance. Given this vast 10k+ parameter space, selecting a power mode for dynamically arriving training workloads to exploit power–performance trade-offs requires costly profiling for each new workload, or is done ad hoc. We propose PowerTrain, a transfer-learning approach to accurately predict the power and time that will be consumed when we train a given DNN workload (model + dataset) using any specified power mode (CPU/GPU/memory frequencies, core-count). It requires a one-time offline profiling of 1000s of power modes for a reference DNN workload on a single Jetson device (Orin AGX) to build Neural Network (NN) based prediction models for time and power. These NN models are subsequently transferred (retrained) for a new DNN workload, or even a different Jetson device, with minimal additional profiling of just 50 power modes to make accurate time and power predictions. These are then used to rapidly construct the Pareto front and select the optimal power mode for the new workload, e.g., to minimize training time while meeting a power limit. PowerTrain’s predictions are robust to new workloads, exhibiting a low MAPE of <6% for power and <15% for time on six new training workloads (MobileNet, YOLO, BERT, LSTM, etc.) for up to 4400 power modes, when transferred from a ResNet reference workload on Orin AGX. It is also resilient when transferred to two entirely new Jetson devices (Xavier AGX and Jetson Orin Nano) with prediction errors of <14.5% and <11%. These outperform baseline predictions by more than 10% and baseline optimizations by up to 45% on time and 88% on power.},
preview = {con-AI.gif}
}
